{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ishaan Mehta E18CSE069 EB02 LabWeek3 Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from local cloud directory\n",
    "data = pd.read_csv('./challenge-week-3-master/data/divorce.csv', sep=';')\n",
    "# Set delimiter to semicolon(;) in case of unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column which has all 1s\n",
    "# The idea is that weight corresponding to this column is equal to intercept\n",
    "# This way it is efficient and easier to handle the bias/intercept term\n",
    "data.insert(0, \"Atr0\", [1]*len(data), allow_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr0</th>\n",
       "      <th>Atr0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atr0  Atr0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  ...  Atr46  \\\n",
       "0     1     1     2     2     4     1     0     0     0     0  ...      2   \n",
       "1     1     1     4     4     4     4     4     0     0     4  ...      2   \n",
       "2     1     1     2     2     2     2     1     3     2     1  ...      3   \n",
       "3     1     1     3     2     3     2     3     3     3     3  ...      2   \n",
       "4     1     1     2     2     1     1     1     1     0     0  ...      2   \n",
       "5     1     1     0     0     1     0     0     2     0     0  ...      2   \n",
       "6     1     1     3     3     3     2     1     3     4     3  ...      3   \n",
       "7     1     1     2     1     2     2     2     1     0     3  ...      0   \n",
       "8     1     1     2     2     1     0     0     4     1     3  ...      1   \n",
       "9     1     1     1     1     1     1     1     2     0     2  ...      2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "5      2      1      2      1      1      1      2      0      1  \n",
       "6      2      3      2      3      3      2      2      2      1  \n",
       "7      1      2      2      2      1      1      1      0      1  \n",
       "8      1      1      1      1      1      1      1      1      1  \n",
       "9      0      2      2      2      2      4      3      3      1  \n",
       "\n",
       "[10 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dataframe rows just to see some samples\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X (input features) and y (output feature) \n",
    "X = data.iloc[:,0:55].values\n",
    "y = np.array(data.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)\n",
      "y: Type-<class 'numpy.ndarray'>, Shape-(170,)\n"
     ]
    }
   ],
   "source": [
    "X_shape = X.shape\n",
    "X_type  = type(X)\n",
    "y_shape = y.shape\n",
    "y_type  = type(y)\n",
    "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
    "print(f'y: Type-{y_type}, Shape-{y_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and fill any missing values if any\n",
    "for v in data.isnull().sum():\n",
    "    if v != 0:\n",
    "        print('Null present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standarization (if required)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar = MinMaxScaler()\n",
    "standardized_features = scalar.fit_transform(X[:, 1:55].copy())\n",
    "dropped = np.delete(X, [i for i in range(1,55)], axis=1)\n",
    "X = np.concatenate((dropped, standardized_features), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (144, 55) , y_train: (144,)\n",
      "X_test: (26, 55) , y_test: (26,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of features and target of training and testing: X_train, X_test, y_train, y_test\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X_test_shape  = X_test.shape\n",
    "y_test_shape  = y_test.shape\n",
    "\n",
    "print(f\"X_train: {X_train_shape} , y_train: {y_train_shape}\")\n",
    "print(f\"X_test: {X_test_shape} , y_test: {y_test_shape}\")\n",
    "assert (X_train.shape[0]==y_train.shape[0] and X_test.shape[0]==y_test.shape[0]), \"Check your splitting carefully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT ANY VARIABLE OR FUNCTION NAME(S) IN THIS CELL\n",
    "# Let's try more object oriented approach this time :)\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000):\n",
    "        '''Initialize variables\n",
    "        Args:\n",
    "            learning_rate  : Learning Rate\n",
    "            max_iterations : Max iterations for training weights\n",
    "        '''\n",
    "        # Initialising all the parameters\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.likelihoods    = []\n",
    "        \n",
    "        # Define epsilon because log(0) is not defined\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        sig_z = 1 / (1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z\n",
    "    \n",
    "    def log_likelihood(self, y_true, y_pred):\n",
    "        '''Calculates maximum likelihood estimate\n",
    "        Remember: y * log(yh) + (1-y) * log(1-yh)\n",
    "        Note: Likelihood is defined for multiple classes as well, but for this dataset\n",
    "        we only need to worry about binary/bernoulli likelihood function\n",
    "        Args:\n",
    "            y_true : Numpy array of actual truth values (num_samples,)\n",
    "            y_pred : Numpy array of predicted values (num_samples,)\n",
    "        Returns:\n",
    "            Log-likelihood, scalar value\n",
    "        '''\n",
    "        # Fix 0/1 values in y_pred so that log is not undefined\n",
    "        y_pred = np.maximum(np.full(y_pred.shape, self.eps), np.minimum(np.full(y_pred.shape, 1-self.eps), y_pred))\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        likelihood =  np.sum(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return likelihood\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''Trains logistic regression model using gradient ascent\n",
    "        to gain maximum likelihood on the training data\n",
    "        Args:\n",
    "            X : Numpy array (num_examples, num_features)\n",
    "            y : Numpy array (num_examples, )\n",
    "        Returns: VOID\n",
    "        '''\n",
    "        \n",
    "        num_examples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        \n",
    "        # Initialize weights with appropriate shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        \n",
    "        # Perform gradient ascent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Define the linear hypothesis(z) first\n",
    "            # HINT: what is our hypothesis function in linear regression, remember?\n",
    "            z = X@self.weights\n",
    "            \n",
    "            # Output probability value by appplying sigmoid on z\n",
    "            y_pred = self.sigmoid(z)\n",
    "            \n",
    "            # Calculate the gradient values\n",
    "            # This is just vectorized efficient way of implementing gradient. Don't worry, we will discuss it later.\n",
    "            gradient = np.mean((y-y_pred)*X.T, axis=1)\n",
    "            \n",
    "            # Update the weights\n",
    "            # Caution: It is gradient ASCENT not descent\n",
    "            self.weights = self.weights + gradient\n",
    "            \n",
    "            # Calculating log likelihood\n",
    "            likelihood = self.log_likelihood(y, y_pred)\n",
    "\n",
    "            self.likelihoods.append(likelihood)\n",
    "    \n",
    "        ### END CODE HERE\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''Predict probabilities for given X.\n",
    "        Remember sigmoid returns value between 0 and 1.\n",
    "        Args:\n",
    "            X : Numpy array (num_samples, num_features)\n",
    "        Returns:\n",
    "            probabilities: Numpy array (num_samples,)\n",
    "        '''\n",
    "        if self.weights is None:\n",
    "            raise Exception(\"Fit the model before prediction\")\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        z = X@self.weights\n",
    "        probabilities = self.sigmoid(z)\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        '''Predict/Classify X in classes\n",
    "        Args:\n",
    "            X         : Numpy array (num_samples, num_features)\n",
    "            threshold : scalar value above which prediction is 1 else 0\n",
    "        Returns:\n",
    "            binary_predictions : Numpy array (num_samples,)\n",
    "        '''\n",
    "        # Thresholding probability to predict binary values\n",
    "        binary_predictions = np.array(pd.DataFrame(self.predict_proba(X)).applymap(lambda x: 1 if x>threshold else 0))\n",
    "        \n",
    "        return binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize logitic regression implemented by you\n",
    "model = MyLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now fit on training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on training data: -0.9930243929565952\n"
     ]
    }
   ],
   "source": [
    "# Train log-likelihood\n",
    "train_log_likelihood = model.log_likelihood(y_train, model.predict_proba(X_train))\n",
    "print(\"Log-likelihood on training data:\", train_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on testing data: -2.8823716485784345\n"
     ]
    }
   ],
   "source": [
    "# Test log-likelihood\n",
    "test_log_likelihood = model.log_likelihood(y_test, model.predict_proba(X_test))\n",
    "print(\"Log-likelihood on testing data:\", test_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(model.likelihoods))], model.likelihoods)\n",
    "plt.title(\"Log-Likelihood curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Log-likelihood\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    '''Compute accuracy.\n",
    "    Accuracy = (Correct prediction / number of samples)\n",
    "    Args:\n",
    "        y_true : Truth binary values (num_examples, )\n",
    "        y_pred : Predicted binary values (num_examples, )\n",
    "    Returns:\n",
    "        accuracy: scalar value\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    n_sample = y_true.shape[0]\n",
    "    c_pred = 0\n",
    "    for i in range(n_sample):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            c_pred+=1\n",
    "    accuracy = c_pred/n_sample\n",
    "    ### END CODE HERE\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on train data\n",
    "print('{:.2f}%'.format(accuracy(y_train, (model.predict(X_train)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.15%\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on test data\n",
    "print('{:.2f}%'.format(accuracy(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = X\n",
    "y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model from sklearn\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on testing set: 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "test_accuracy_sklearn = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy on testing set: {test_accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
